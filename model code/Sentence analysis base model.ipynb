{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8007\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn\n",
    "import time\n",
    "import gc\n",
    "\n",
    "#load sentencepiece model\n",
    "vocab_file = \"VocabModel/kowiki.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size:  46498\n",
      "test dataset size:  5812\n",
      "train dataset size:  46498\n",
      "validation dataset size:  5812\n",
      "test dataset size:  5812\n"
     ]
    }
   ],
   "source": [
    "max_size = 128\n",
    "batch_size = 512\n",
    "\n",
    "class CustomDataSetPadding(data.Dataset):\n",
    "    def __init__(self, file_name):\n",
    "        self.data = pd.read_csv(file_name)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        line = self.data.loc[index]\n",
    "        sentence = line[\"Sentence\"]\n",
    "        emotion = line[\"Emotion\"]\n",
    "        emotion = emotion[1:-1].split(\", \")\n",
    "        for i in range(len(emotion)):\n",
    "            emotion[i] = float(emotion[i])\n",
    "        a = emotion.index(max(emotion))\n",
    "        # 라벨을 one hot encoding 형태로 변환\n",
    "        emotion = [0, 0, 0, 0, 0, 0, 0]\n",
    "        emotion[a] = 1\n",
    "        # 문장을 형태로 단위로 분할\n",
    "        ids = vocab.encode_as_ids(sentence)\n",
    "\n",
    "        if len(ids) > max_size:\n",
    "            ids = ids[0:max_size-1]\n",
    "        for idx in range(max_size-len(ids)):\n",
    "            ids.insert(0, 0)\n",
    "\n",
    "        ids = [ids]\n",
    "        ids = torch.tensor(ids)\n",
    "        emotion= torch.tensor(emotion)\n",
    "        return ids, emotion\n",
    "\n",
    "#zero padding\n",
    "dataset = CustomDataSetPadding(\"datasets/original data/음성대화모음집.csv\")\n",
    "train_size = int(dataset.__len__() * 0.8) #30876\n",
    "validation_size = int(dataset.__len__()* 0.1)\n",
    "test_size = int(dataset.__len__() * 0.1) #7718\n",
    "train_size += dataset.__len__() - train_size - test_size - validation_size\n",
    "\n",
    "train_dataset , validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size,test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"train dataset size: \", len(train_dataset))\n",
    "print(\"validation dataset size: \", len(validation_dataset))\n",
    "print(\"test dataset size: \", len(test_dataset))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "device name: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "device count: 1\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_name = torch.cuda.get_device_name(0)\n",
    "device_count = torch.cuda.device_count()\n",
    "\n",
    "print(f\"device: {device}\\ndevice name: {device_name}\\ndevice count: {device_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, output_dim, num_layers, bias, batch_first, dropout, bidirectional, proj_size):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.LSTM1 = nn.LSTM(input_size= input_dim,\n",
    "                            hidden_size= emb_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            bias = bias,\n",
    "                            batch_first=batch_first,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=bidirectional,\n",
    "                            proj_size=proj_size)\n",
    "\n",
    "        self.LSTM2 = nn.LSTM(input_size= emb_dim,\n",
    "                            hidden_size= emb_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            bias = bias,\n",
    "                            batch_first=batch_first,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=bidirectional,\n",
    "                            proj_size=proj_size)\n",
    "\n",
    "        self.LSTM3 = nn.LSTM(input_size= emb_dim,\n",
    "                            hidden_size= emb_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            bias = bias,\n",
    "                            batch_first=batch_first,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=bidirectional,\n",
    "                            proj_size=proj_size)\n",
    "\n",
    "        self.linear = nn.Linear(emb_dim, output_dim)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output, (ht, ct) = self.LSTM1(input)\n",
    "        output, (ht, ct) = self.LSTM2(output, (ht, ct))\n",
    "        output, (_, _) = self.LSTM3(output, (ht, ct))\n",
    "        output = self.linear(output) #output = self.linear(ht[-1])\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample input size:  torch.Size([512, 1, 128])\n",
      "tensor([[[   0,    0,    0,  ...,   32,  849, 4311]],\n",
      "\n",
      "        [[   0,    0,    0,  ..., 4313, 3639, 4311]],\n",
      "\n",
      "        [[   0,    0,    0,  ...,  513, 3663, 3629]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[   0,    0,    0,  ..., 3350, 3663, 3629]],\n",
      "\n",
      "        [[   0,    0,    0,  ..., 3807,  302, 4311]],\n",
      "\n",
      "        [[   0,    0,    0,  ..., 6051, 3659, 3629]]])\n",
      "sample label size:  torch.Size([512, 7])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 1,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 1, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 0, 0],\n",
      "        [0, 1, 0,  ..., 0, 0, 0],\n",
      "        [0, 1, 0,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#train parameters\n",
    "lr = 0.001\n",
    "epochs = 250\n",
    "\n",
    "# lstm parameters\n",
    "emb_dim = 512\n",
    "out_dim = 7\n",
    "num_layers = 1\n",
    "bias = True\n",
    "batch_first = True #N:batch size L:sequence Length Hin:input size\n",
    "dropout = 0\n",
    "bidirectional = False\n",
    "proj_size = 0\n",
    "\n",
    "model = LSTMCell(max_size,\n",
    "                    emb_dim,\n",
    "                    out_dim,\n",
    "                    num_layers,\n",
    "                    bias,\n",
    "                    batch_first,\n",
    "                    dropout,\n",
    "                    bidirectional,\n",
    "                    proj_size).to(device)\n",
    "\n",
    "batch, (text, emo) = next(enumerate(train_dataloader))\n",
    "\n",
    "print(\"sample input size: \", text.size())\n",
    "print(text)\n",
    "print(\"sample label size: \", emo.size())\n",
    "print(emo)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] \t loss = 1.6263 \t correct 0.3828 \t time = 6.1800\n",
      "[Epoch:    2] \t loss = 1.5742 \t correct 0.3976 \t time = 5.9640\n",
      "[Epoch:    3] \t loss = 1.5642 \t correct 0.4028 \t time = 5.9701\n",
      "[Epoch:    4] \t loss = 1.5469 \t correct 0.4061 \t time = 5.8519\n",
      "[Epoch:    5] \t loss = 1.5320 \t correct 0.4085 \t time = 6.0040\n",
      "[Epoch:    6] \t loss = 1.5258 \t correct 0.3987 \t time = 5.9090\n",
      "[Epoch:    7] \t loss = 1.5133 \t correct 0.4246 \t time = 5.9090\n",
      "[Epoch:    8] \t loss = 1.4975 \t correct 0.4289 \t time = 6.0170\n",
      "[Epoch:    9] \t loss = 1.4805 \t correct 0.4355 \t time = 5.8917\n",
      "[Epoch:   10] \t loss = 1.4600 \t correct 0.4424 \t time = 5.9731\n",
      "[Epoch:   11] \t loss = 1.4449 \t correct 0.4491 \t time = 6.0270\n",
      "[Epoch:   12] \t loss = 1.4217 \t correct 0.4403 \t time = 5.9660\n",
      "[Epoch:   13] \t loss = 1.4037 \t correct 0.4639 \t time = 5.9700\n",
      "[Epoch:   14] \t loss = 1.3850 \t correct 0.4670 \t time = 5.8880\n",
      "[Epoch:   15] \t loss = 1.3542 \t correct 0.4683 \t time = 5.9800\n",
      "[Epoch:   16] \t loss = 1.3305 \t correct 0.4811 \t time = 5.9400\n",
      "[Epoch:   17] \t loss = 1.3247 \t correct 0.4780 \t time = 5.9640\n",
      "[Epoch:   18] \t loss = 1.3047 \t correct 0.4943 \t time = 5.9370\n",
      "[Epoch:   19] \t loss = 1.2749 \t correct 0.4904 \t time = 5.9190\n",
      "[Epoch:   20] \t loss = 1.2522 \t correct 0.5010 \t time = 5.9330\n",
      "[Epoch:   21] \t loss = 1.2352 \t correct 0.5036 \t time = 5.9310\n",
      "[Epoch:   22] \t loss = 1.2089 \t correct 0.5131 \t time = 6.0250\n",
      "[Epoch:   23] \t loss = 1.1661 \t correct 0.5232 \t time = 5.8850\n",
      "[Epoch:   24] \t loss = 1.1228 \t correct 0.5416 \t time = 6.0050\n",
      "[Epoch:   25] \t loss = 1.0961 \t correct 0.5470 \t time = 6.0150\n",
      "[Epoch:   26] \t loss = 1.0830 \t correct 0.5470 \t time = 5.8990\n",
      "[Epoch:   27] \t loss = 1.0647 \t correct 0.5611 \t time = 5.9600\n",
      "[Epoch:   28] \t loss = 1.0097 \t correct 0.5702 \t time = 5.8680\n",
      "[Epoch:   29] \t loss = 0.9868 \t correct 0.5824 \t time = 6.0430\n",
      "[Epoch:   30] \t loss = 0.9535 \t correct 0.5931 \t time = 5.9700\n",
      "[Epoch:   31] \t loss = 0.9440 \t correct 0.6007 \t time = 5.9270\n",
      "[Epoch:   32] \t loss = 0.9085 \t correct 0.6170 \t time = 6.0610\n",
      "[Epoch:   33] \t loss = 0.8935 \t correct 0.6199 \t time = 5.9390\n",
      "[Epoch:   34] \t loss = 0.8537 \t correct 0.6333 \t time = 6.0470\n",
      "[Epoch:   35] \t loss = 0.7976 \t correct 0.6497 \t time = 5.8490\n",
      "[Epoch:   36] \t loss = 0.7830 \t correct 0.6536 \t time = 5.9240\n",
      "[Epoch:   37] \t loss = 0.7726 \t correct 0.6585 \t time = 5.9400\n",
      "[Epoch:   38] \t loss = 0.7324 \t correct 0.6624 \t time = 5.9320\n",
      "[Epoch:   39] \t loss = 0.7263 \t correct 0.6850 \t time = 6.0159\n",
      "[Epoch:   40] \t loss = 0.6896 \t correct 0.6870 \t time = 6.0245\n",
      "[Epoch:   41] \t loss = 0.6775 \t correct 0.6855 \t time = 5.9600\n",
      "[Epoch:   42] \t loss = 0.6514 \t correct 0.7125 \t time = 5.8970\n",
      "[Epoch:   43] \t loss = 0.6237 \t correct 0.7190 \t time = 6.0491\n",
      "[Epoch:   44] \t loss = 0.6044 \t correct 0.7306 \t time = 5.9730\n",
      "[Epoch:   45] \t loss = 0.5966 \t correct 0.7343 \t time = 5.9830\n",
      "[Epoch:   46] \t loss = 0.5602 \t correct 0.7433 \t time = 5.9631\n",
      "[Epoch:   47] \t loss = 0.5571 \t correct 0.7459 \t time = 5.9300\n",
      "[Epoch:   48] \t loss = 0.5392 \t correct 0.7553 \t time = 5.9489\n",
      "[Epoch:   49] \t loss = 0.5297 \t correct 0.7498 \t time = 5.9270\n",
      "[Epoch:   50] \t loss = 0.5105 \t correct 0.7567 \t time = 5.8750\n",
      "[Epoch:   51] \t loss = 0.5113 \t correct 0.7650 \t time = 5.9320\n",
      "[Epoch:   52] \t loss = 0.5010 \t correct 0.7701 \t time = 5.9358\n",
      "[Epoch:   53] \t loss = 0.4818 \t correct 0.7830 \t time = 6.0160\n",
      "[Epoch:   54] \t loss = 0.4606 \t correct 0.7858 \t time = 5.9362\n",
      "[Epoch:   55] \t loss = 0.4430 \t correct 0.8004 \t time = 6.0000\n",
      "[Epoch:   56] \t loss = 0.4237 \t correct 0.7968 \t time = 5.9890\n",
      "[Epoch:   57] \t loss = 0.4329 \t correct 0.8042 \t time = 5.9560\n",
      "[Epoch:   58] \t loss = 0.4040 \t correct 0.8119 \t time = 5.9770\n",
      "[Epoch:   59] \t loss = 0.4218 \t correct 0.8121 \t time = 5.9390\n",
      "[Epoch:   60] \t loss = 0.4173 \t correct 0.8035 \t time = 5.9690\n",
      "[Epoch:   61] \t loss = 0.4050 \t correct 0.8057 \t time = 5.9330\n",
      "[Epoch:   62] \t loss = 0.4094 \t correct 0.8152 \t time = 5.9270\n",
      "[Epoch:   63] \t loss = 0.3955 \t correct 0.8228 \t time = 5.9550\n",
      "[Epoch:   64] \t loss = 0.3906 \t correct 0.8204 \t time = 6.0250\n",
      "[Epoch:   65] \t loss = 0.3907 \t correct 0.8217 \t time = 5.9800\n",
      "[Epoch:   66] \t loss = 0.4007 \t correct 0.8224 \t time = 5.8920\n",
      "[Epoch:   67] \t loss = 0.3928 \t correct 0.8109 \t time = 5.9780\n",
      "[Epoch:   68] \t loss = 0.4043 \t correct 0.8100 \t time = 5.9280\n",
      "[Epoch:   69] \t loss = 0.3824 \t correct 0.8377 \t time = 6.0100\n",
      "[Epoch:   70] \t loss = 0.3530 \t correct 0.8407 \t time = 6.0300\n",
      "[Epoch:   71] \t loss = 0.3436 \t correct 0.8422 \t time = 5.9640\n",
      "[Epoch:   72] \t loss = 0.3409 \t correct 0.8415 \t time = 6.0210\n",
      "[Epoch:   73] \t loss = 0.3460 \t correct 0.8493 \t time = 5.9229\n",
      "[Epoch:   74] \t loss = 0.3486 \t correct 0.8374 \t time = 5.8555\n",
      "[Epoch:   75] \t loss = 0.3540 \t correct 0.8417 \t time = 6.0040\n",
      "[Epoch:   76] \t loss = 0.3488 \t correct 0.8519 \t time = 5.9390\n",
      "[Epoch:   77] \t loss = 0.3477 \t correct 0.8317 \t time = 6.0180\n",
      "[Epoch:   78] \t loss = 0.3433 \t correct 0.8494 \t time = 5.9290\n",
      "[Epoch:   79] \t loss = 0.3289 \t correct 0.8524 \t time = 5.9720\n",
      "[Epoch:   80] \t loss = 0.3266 \t correct 0.8520 \t time = 5.9751\n",
      "[Epoch:   81] \t loss = 0.3193 \t correct 0.8558 \t time = 5.9260\n",
      "[Epoch:   82] \t loss = 0.3418 \t correct 0.8331 \t time = 5.9740\n",
      "[Epoch:   83] \t loss = 0.3545 \t correct 0.8271 \t time = 5.9680\n",
      "[Epoch:   84] \t loss = 0.3686 \t correct 0.8298 \t time = 5.9827\n",
      "[Epoch:   85] \t loss = 0.3634 \t correct 0.8384 \t time = 5.9260\n",
      "[Epoch:   86] \t loss = 0.3523 \t correct 0.8248 \t time = 5.9390\n",
      "[Epoch:   87] \t loss = 0.3586 \t correct 0.8396 \t time = 6.0030\n",
      "[Epoch:   88] \t loss = 0.3673 \t correct 0.8439 \t time = 5.9670\n",
      "[Epoch:   89] \t loss = 0.3493 \t correct 0.8371 \t time = 6.0200\n",
      "[Epoch:   90] \t loss = 0.3659 \t correct 0.8364 \t time = 6.0730\n",
      "[Epoch:   91] \t loss = 0.3583 \t correct 0.8436 \t time = 6.0470\n",
      "[Epoch:   92] \t loss = 0.3556 \t correct 0.8412 \t time = 5.9250\n",
      "[Epoch:   93] \t loss = 0.3356 \t correct 0.8527 \t time = 5.8936\n",
      "[Epoch:   94] \t loss = 0.3355 \t correct 0.8381 \t time = 5.9770\n",
      "[Epoch:   95] \t loss = 0.3418 \t correct 0.8476 \t time = 5.9280\n",
      "[Epoch:   96] \t loss = 0.3341 \t correct 0.8381 \t time = 5.9720\n",
      "[Epoch:   97] \t loss = 0.3369 \t correct 0.8472 \t time = 5.8850\n",
      "[Epoch:   98] \t loss = 0.3298 \t correct 0.8396 \t time = 6.0240\n",
      "[Epoch:   99] \t loss = 0.3330 \t correct 0.8482 \t time = 6.0140\n",
      "[Epoch:  100] \t loss = 0.3164 \t correct 0.8570 \t time = 5.9301\n",
      "[Epoch:  101] \t loss = 0.3111 \t correct 0.8470 \t time = 6.0955\n",
      "[Epoch:  102] \t loss = 0.3186 \t correct 0.8611 \t time = 5.9731\n",
      "[Epoch:  103] \t loss = 0.3078 \t correct 0.8620 \t time = 5.9700\n",
      "[Epoch:  104] \t loss = 0.3075 \t correct 0.8522 \t time = 5.9329\n",
      "[Epoch:  105] \t loss = 0.3058 \t correct 0.8596 \t time = 5.8560\n",
      "[Epoch:  106] \t loss = 0.3076 \t correct 0.8613 \t time = 6.0870\n",
      "[Epoch:  107] \t loss = 0.3003 \t correct 0.8598 \t time = 5.9040\n",
      "[Epoch:  108] \t loss = 0.2945 \t correct 0.8594 \t time = 6.0330\n",
      "[Epoch:  109] \t loss = 0.3030 \t correct 0.8565 \t time = 5.8780\n",
      "[Epoch:  110] \t loss = 0.3004 \t correct 0.8660 \t time = 5.9080\n",
      "[Epoch:  111] \t loss = 0.2910 \t correct 0.8673 \t time = 6.0210\n",
      "[Epoch:  112] \t loss = 0.2918 \t correct 0.8617 \t time = 5.9650\n",
      "[Epoch:  113] \t loss = 0.2866 \t correct 0.8611 \t time = 5.9020\n",
      "[Epoch:  114] \t loss = 0.2842 \t correct 0.8687 \t time = 5.8820\n",
      "[Epoch:  115] \t loss = 0.2770 \t correct 0.8684 \t time = 5.9691\n",
      "[Epoch:  116] \t loss = 0.2937 \t correct 0.8548 \t time = 5.9799\n",
      "[Epoch:  117] \t loss = 0.2994 \t correct 0.8575 \t time = 6.0360\n",
      "[Epoch:  118] \t loss = 0.2955 \t correct 0.8727 \t time = 5.9990\n",
      "[Epoch:  119] \t loss = 0.2917 \t correct 0.8596 \t time = 5.8860\n",
      "[Epoch:  120] \t loss = 0.3019 \t correct 0.8603 \t time = 5.9760\n",
      "[Epoch:  121] \t loss = 0.3067 \t correct 0.8538 \t time = 6.0080\n",
      "[Epoch:  122] \t loss = 0.3069 \t correct 0.8500 \t time = 5.9410\n",
      "[Epoch:  123] \t loss = 0.3186 \t correct 0.8589 \t time = 5.9700\n",
      "[Epoch:  124] \t loss = 0.3096 \t correct 0.8617 \t time = 5.9650\n",
      "[Epoch:  125] \t loss = 0.2960 \t correct 0.8577 \t time = 6.0580\n",
      "[Epoch:  126] \t loss = 0.2818 \t correct 0.8667 \t time = 5.8520\n",
      "[Epoch:  127] \t loss = 0.2848 \t correct 0.8735 \t time = 6.0110\n",
      "[Epoch:  128] \t loss = 0.2854 \t correct 0.8665 \t time = 5.9340\n",
      "[Epoch:  129] \t loss = 0.2930 \t correct 0.8660 \t time = 5.9310\n",
      "[Epoch:  130] \t loss = 0.2971 \t correct 0.8598 \t time = 6.0970\n",
      "[Epoch:  131] \t loss = 0.2942 \t correct 0.8603 \t time = 5.8510\n",
      "[Epoch:  132] \t loss = 0.2986 \t correct 0.8665 \t time = 5.9650\n",
      "[Epoch:  133] \t loss = 0.2942 \t correct 0.8718 \t time = 6.0250\n",
      "[Epoch:  134] \t loss = 0.2856 \t correct 0.8735 \t time = 6.0090\n",
      "[Epoch:  135] \t loss = 0.2800 \t correct 0.8732 \t time = 5.8505\n",
      "[Epoch:  136] \t loss = 0.2755 \t correct 0.8713 \t time = 5.9690\n",
      "[Epoch:  137] \t loss = 0.2647 \t correct 0.8792 \t time = 5.9710\n",
      "[Epoch:  138] \t loss = 0.2725 \t correct 0.8727 \t time = 5.9390\n",
      "[Epoch:  139] \t loss = 0.2762 \t correct 0.8655 \t time = 6.0540\n",
      "[Epoch:  140] \t loss = 0.2802 \t correct 0.8844 \t time = 5.9720\n",
      "[Epoch:  141] \t loss = 0.2815 \t correct 0.8622 \t time = 5.8940\n",
      "[Epoch:  142] \t loss = 0.2957 \t correct 0.8685 \t time = 6.0260\n",
      "[Epoch:  143] \t loss = 0.3035 \t correct 0.8661 \t time = 5.9750\n",
      "[Epoch:  144] \t loss = 0.2951 \t correct 0.8625 \t time = 5.9210\n",
      "[Epoch:  145] \t loss = 0.2995 \t correct 0.8673 \t time = 5.8835\n",
      "[Epoch:  146] \t loss = 0.2893 \t correct 0.8629 \t time = 6.0100\n",
      "[Epoch:  147] \t loss = 0.2886 \t correct 0.8689 \t time = 5.9360\n",
      "[Epoch:  148] \t loss = 0.2832 \t correct 0.8601 \t time = 5.9250\n",
      "[Epoch:  149] \t loss = 0.2969 \t correct 0.8682 \t time = 5.9480\n",
      "[Epoch:  150] \t loss = 0.2965 \t correct 0.8715 \t time = 5.9180\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_24224\\3908918622.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     45\u001B[0m             \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"models/lstm_encoder_onehot_3layer_batch512.cpkt\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m         '''\n\u001B[1;32m---> 47\u001B[1;33m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_dataloader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_dataloader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_24224\\3908918622.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(train_dataloader, val_dataloader, model, epochs, lr)\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[0mcount\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0mcorrect\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0memo\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_dataloader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m             \u001B[0mtext\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mFloatTensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m             \u001B[0memo\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0memo\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mFloatTensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    626\u001B[0m                 \u001B[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    627\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 628\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    629\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    630\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    669\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    670\u001B[0m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 671\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    672\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    673\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory_device\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     59\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcollate_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001B[0m in \u001B[0;36mdefault_collate\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m    263\u001B[0m             \u001B[1;33m>>\u001B[0m\u001B[1;33m>\u001B[0m \u001B[0mdefault_collate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Handle `CustomType` automatically\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    264\u001B[0m     \"\"\"\n\u001B[1;32m--> 265\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mcollate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcollate_fn_map\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdefault_collate_fn_map\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001B[0m in \u001B[0;36mcollate\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    142\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0melem\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 143\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mcollate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msamples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcollate_fn_map\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcollate_fn_map\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0msamples\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtransposed\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m# Backwards compatibility.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    144\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    145\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    142\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0melem\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 143\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mcollate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msamples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcollate_fn_map\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcollate_fn_map\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0msamples\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtransposed\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m# Backwards compatibility.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    144\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    145\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001B[0m in \u001B[0;36mcollate\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    118\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcollate_fn_map\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    119\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0melem_type\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcollate_fn_map\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 120\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mcollate_fn_map\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0melem_type\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcollate_fn_map\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcollate_fn_map\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    121\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    122\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mcollate_type\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcollate_fn_map\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001B[0m in \u001B[0;36mcollate_tensor_fn\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    161\u001B[0m         \u001B[0mstorage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0melem\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstorage\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_new_shared\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnumel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0melem\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0melem\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnew\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstorage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresize_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0melem\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 163\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    164\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    165\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model_dict = 0\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "test_loss2 = []\n",
    "\n",
    "def train(train_dataloader, val_dataloader, model, epochs, lr):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_correction = 0\n",
    "    for epoch in range(epochs):\n",
    "        now = time.time()\n",
    "        avg_loss = 0\n",
    "        total_batch = len(train_dataloader) #965\n",
    "        count = 0\n",
    "        correct = 0\n",
    "        for batch, (text, emo) in enumerate(train_dataloader):\n",
    "            text = text.type(torch.FloatTensor).to(device)\n",
    "            emo = emo.type(torch.FloatTensor).to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(text)\n",
    "            pred = torch.squeeze(pred, 1)\n",
    "            loss = criterion(pred, emo)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss / total_batch\n",
    "        with torch.no_grad():\n",
    "            for batch, (text, emo) in enumerate(val_dataloader):\n",
    "                text = text.type(torch.FloatTensor).to(device)\n",
    "                emo = emo.type(torch.FloatTensor).to(device)\n",
    "                pred = model(text)\n",
    "                pred = torch.squeeze(pred, 1)\n",
    "                for i in range(pred.size()[0]):\n",
    "                    count += 1\n",
    "                    if torch.argmax(pred[i]) == torch.argmax(emo[i]):\n",
    "                        correct += 1\n",
    "        print(\"[Epoch: {:>4}] \\t loss = {:.4f} \\t correct {:.4f} \\t time = {:.4f}\"\n",
    "              .format(epoch + 1, avg_loss.data, correct/count ,time.time()-now))\n",
    "        ''' # save model\n",
    "        if(correct/count > best_correction):\n",
    "            best_correction = correct/count\n",
    "            torch.save(model.state_dict(), \"models/lstm_encoder_onehot_3layer_batch512.cpkt\")\n",
    "        '''\n",
    "train(train_dataloader, validation_dataloader, model, epochs, lr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result:  85.92567102546455 time =  1.3069953918457031\n"
     ]
    }
   ],
   "source": [
    "def test(dataloader, model):\n",
    "    model.eval()\n",
    "    now = time.time()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        for batch, (text, emo) in enumerate(dataloader):\n",
    "            text = text.type(torch.FloatTensor).to(device)\n",
    "            emo = emo.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            pred = model(text)\n",
    "            pred = torch.squeeze(pred, 1)\n",
    "            for i in range(pred.size()[0]):\n",
    "               count += 1\n",
    "               if torch.argmax(pred[i]) == torch.argmax(emo[i]):\n",
    "                   correct += 1\n",
    "        print(\"Test result: \", correct/count*100, \"time = \", time.time() - now)\n",
    "\n",
    "test(test_dataloader, model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
